{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reinaldi09/Two-way-communication-using-deepspeech/blob/main/Salinan_dari_DeepSpeech_Training_with_own_scorer_Indonesia_10_3_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42xAFf0_W7Hy"
      },
      "source": [
        "# Mounting gdrive dan clone github deepspeech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGZbcsRzkUmf",
        "outputId": "9d34c4d1-77f0-450b-872c-21f68db86bed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCVFOJ4amMZJ",
        "outputId": "b2b4a78d-7653-41c7-a600-94e279033399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepSpeech'...\n",
            "remote: Enumerating objects: 23888, done.\u001b[K\n",
            "remote: Total 23888 (delta 0), reused 0 (delta 0), pack-reused 23888\u001b[K\n",
            "Receiving objects: 100% (23888/23888), 49.36 MiB | 23.21 MiB/s, done.\n",
            "Resolving deltas: 100% (16417/16417), done.\n",
            "Note: checking out 'f2e9c85880dff94115ab510cde9ca4af7ee51c19'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!git clone --branch v0.9.3 https://github.com/mozilla/DeepSpeech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPwLTrCVAvgM",
        "outputId": "813575c2-2f18-48ed-d936-7a5c17dfe340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "The name is too long, 1210 chars total.\n",
            "Trying to shorten...\n",
            "New name is cv-corpus-8.0-2022-01-19-id.tar.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAQ3GQRTO3FGCAZL7J%2F20220314%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220314T052245Z&X-Amz-Expires=43200&X-Amz-Security-Token=FwoGZXIvYXdzEO7%2F.\n",
            "--2022-03-14 05:23:04--  https://mozilla-common-voice-datasets.s3.dualstack.us-west-2.amazonaws.com/cv-corpus-8.0-2022-01-19/cv-corpus-8.0-2022-01-19-id.tar.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAQ3GQRTO3FGCAZL7J%2F20220314%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220314T052245Z&X-Amz-Expires=43200&X-Amz-Security-Token=FwoGZXIvYXdzEO7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDCbyj6H1R1jqpj2n0yKSBCdhoYpdmksEPBcrtItczC90F7ES0aYCESx5%2F3tRRddx1N%2Bj65RHVU62F4PWB6kgtOyCQVVnKH0cEcQG%2FI9l2GvLYFp3XYc3%2FNjHul0Z0GbZ6ZPBI2OTwA62QDmRfsD9s%2B2dPJ7jNhgDLWKgkTZ3hEZ5tunDb8zm7BlOEMukRoYQcXQJxdGhZr%2FC4vhc99D%2BmExQm29F0bUNO9ISnxAHfEuWF1z%2BJPUgl3%2B5j48pxCNZTu7Jer74PSPX6S2lWCcNkZKO2VXJaDzwjed%2FC0l9yBm9PXhztOXsni7EdY%2Fj2wSwqQ8AMOushN2FhlRfhEwR646ed2w4Lp%2BVRUyVGeJRT%2BROwhFjW%2BTofhNelTlRml0Voi12XQdhRR%2F%2Fpp45Cqd5p7zWt7i4KEwQlNIkJbxmC9D9z8DUK2aJnTK%2BDrk7koWC0Paike6IurhU0iHIdIK%2B2GvzY%2FqhZGW8ljj2SVG%2BNN4RuDTnZ5s9TTcg98%2FFX2ALd0MqaM7IQnR%2F2KG3DPSA03foffT3dGFAtkZWWZ%2Bz%2B3wFuOB3VvF55LY4Xa2KRHFRVOC9MkCnYynogzK8%2FepWb0zWG%2FGq43FwoBu0FnHa1VB1YdjPZVI2fWnYbTOoUZGbjD%2FIiJ8Ty%2Fu1%2Bq%2FqKPOKB5%2F8GReOfpiCzeUeJtp%2FWjOpf3aGr9pNf5I%2B7NQEw51cMe%2BQglRNvLta%2FXokkJZkHH7WKNKVu5EGMiodk9JWrTHP%2Fi%2F4AKpeD43%2BgMevdNvGiAHSx90Bi5HbMYB29CVTpvWy9F0%3D&X-Amz-Signature=b7dc1568912944420fd387d886623bf56cda80a28c0364d26d5f93bb47acced5&X-Amz-SignedHeaders=host\n",
            "Resolving mozilla-common-voice-datasets.s3.dualstack.us-west-2.amazonaws.com (mozilla-common-voice-datasets.s3.dualstack.us-west-2.amazonaws.com)... 52.218.137.49, 2600:1fa0:40ac:10c1:34da:e509::\n",
            "Connecting to mozilla-common-voice-datasets.s3.dualstack.us-west-2.amazonaws.com (mozilla-common-voice-datasets.s3.dualstack.us-west-2.amazonaws.com)|52.218.137.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1237534480 (1.2G) [application/octet-stream]\n",
            "Saving to: ‘cv-corpus-8.0-2022-01-19-id.tar.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAQ3GQRTO3FGCAZL7J%2F20220314%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220314T052245Z&X-Amz-Expires=43200&X-Amz-Security-Token=FwoGZXIvYXdzEO7%2F’\n",
            "\n",
            "cv-corpus-8.0-2022- 100%[===================>]   1.15G  45.1MB/s    in 27s     \n",
            "\n",
            "2022-03-14 05:23:31 (43.6 MB/s) - ‘cv-corpus-8.0-2022-01-19-id.tar.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAQ3GQRTO3FGCAZL7J%2F20220314%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220314T052245Z&X-Amz-Expires=43200&X-Amz-Security-Token=FwoGZXIvYXdzEO7%2F’ saved [1237534480/1237534480]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!wget -c \"https://mozilla-common-voice-datasets.s3.dualstack.us-west-2.amazonaws.com/cv-corpus-8.0-2022-01-19/cv-corpus-8.0-2022-01-19-id.tar.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAQ3GQRTO3FGCAZL7J%2F20220314%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220314T052245Z&X-Amz-Expires=43200&X-Amz-Security-Token=FwoGZXIvYXdzEO7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDCbyj6H1R1jqpj2n0yKSBCdhoYpdmksEPBcrtItczC90F7ES0aYCESx5%2F3tRRddx1N%2Bj65RHVU62F4PWB6kgtOyCQVVnKH0cEcQG%2FI9l2GvLYFp3XYc3%2FNjHul0Z0GbZ6ZPBI2OTwA62QDmRfsD9s%2B2dPJ7jNhgDLWKgkTZ3hEZ5tunDb8zm7BlOEMukRoYQcXQJxdGhZr%2FC4vhc99D%2BmExQm29F0bUNO9ISnxAHfEuWF1z%2BJPUgl3%2B5j48pxCNZTu7Jer74PSPX6S2lWCcNkZKO2VXJaDzwjed%2FC0l9yBm9PXhztOXsni7EdY%2Fj2wSwqQ8AMOushN2FhlRfhEwR646ed2w4Lp%2BVRUyVGeJRT%2BROwhFjW%2BTofhNelTlRml0Voi12XQdhRR%2F%2Fpp45Cqd5p7zWt7i4KEwQlNIkJbxmC9D9z8DUK2aJnTK%2BDrk7koWC0Paike6IurhU0iHIdIK%2B2GvzY%2FqhZGW8ljj2SVG%2BNN4RuDTnZ5s9TTcg98%2FFX2ALd0MqaM7IQnR%2F2KG3DPSA03foffT3dGFAtkZWWZ%2Bz%2B3wFuOB3VvF55LY4Xa2KRHFRVOC9MkCnYynogzK8%2FepWb0zWG%2FGq43FwoBu0FnHa1VB1YdjPZVI2fWnYbTOoUZGbjD%2FIiJ8Ty%2Fu1%2Bq%2FqKPOKB5%2F8GReOfpiCzeUeJtp%2FWjOpf3aGr9pNf5I%2B7NQEw51cMe%2BQglRNvLta%2FXokkJZkHH7WKNKVu5EGMiodk9JWrTHP%2Fi%2F4AKpeD43%2BgMevdNvGiAHSx90Bi5HbMYB29CVTpvWy9F0%3D&X-Amz-Signature=b7dc1568912944420fd387d886623bf56cda80a28c0364d26d5f93bb47acced5&X-Amz-SignedHeaders=host\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlUDda_IXHgw"
      },
      "source": [
        "**Ekstrak File Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zB2lAM4wBvdg"
      },
      "outputs": [],
      "source": [
        "!tar -xf /content/cv-corpus-8.0-2022-01-19-id.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4Xx3AbXXhDU"
      },
      "source": [
        "# Install Requirements untuk deepspeech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSeSCKAmZ5t3"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "# ! sudo apt-get install git-lfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbESGHRXaBBf"
      },
      "outputs": [],
      "source": [
        "# %cd /content/gdrive/MyDrive/DeepSpeech\n",
        "# ! git lfs pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9EYWZmvaBzn"
      },
      "outputs": [],
      "source": [
        "# ! pip3 install virtualenv\n",
        "# ! virtualenv -p python3 $HOME/tmp/deepspeech-train-venv/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9sQZMmVaHJO"
      },
      "outputs": [],
      "source": [
        "# ! source $HOME/tmp/deepspeech-train-venv/bin/activate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs_zJUZlaJ99"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e4bxNm5Ym8HQ",
        "outputId": "088dc01a-f03f-4bca-c0b6-12b1dd3f04e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSpeech\n",
            "Collecting absl-py==0.9.0\n",
            "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting attrdict==2.0.1\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Collecting deepspeech\n",
            "  Downloading deepspeech-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (9.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2 MB 35.0 MB/s \n",
            "\u001b[?25hCollecting numpy==1.16.0\n",
            "  Downloading numpy-1.16.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 89 kB/s \n",
            "\u001b[?25hCollecting progressbar2==3.47.0\n",
            "  Downloading progressbar2-3.47.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting python-utils==2.3.0\n",
            "  Downloading python_utils-2.3.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting six==1.13.0\n",
            "  Downloading six-1.13.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pandas==0.25.3\n",
            "  Downloading pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 36.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->-r requirements_eval_tflite.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->-r requirements_eval_tflite.txt (line 8)) (2018.9)\n",
            "Building wheels for collected packages: absl-py\n",
            "  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121939 sha256=f5f7dbaeaa87b9a10d57272e108bfaae19c586f7cc07b7526f42f30d78a8de9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/af/1a/498a24d0730ef484019e007bb9e8cef3ac00311a672c049a3e\n",
            "Successfully built absl-py\n",
            "Installing collected packages: six, python-utils, numpy, progressbar2, pandas, deepspeech, attrdict, absl-py\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: python-utils\n",
            "    Found existing installation: python-utils 3.1.0\n",
            "    Uninstalling python-utils-3.1.0:\n",
            "      Successfully uninstalled python-utils-3.1.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "  Attempting uninstall: progressbar2\n",
            "    Found existing installation: progressbar2 3.38.0\n",
            "    Uninstalling progressbar2-3.38.0:\n",
            "      Successfully uninstalled progressbar2-3.38.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.0.0\n",
            "    Uninstalling absl-py-1.0.0:\n",
            "      Successfully uninstalled absl-py-1.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "xarray 0.18.2 requires numpy>=1.17, but you have numpy 1.16.0 which is incompatible.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.16.0 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.16.0 which is incompatible.\n",
            "scikit-image 0.18.3 requires numpy>=1.16.5, but you have numpy 1.16.0 which is incompatible.\n",
            "pywavelets 1.2.0 requires numpy>=1.17.3, but you have numpy 1.16.0 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.16.0 which is incompatible.\n",
            "pyarrow 6.0.1 requires numpy>=1.16.6, but you have numpy 1.16.0 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.16.0 which is incompatible.\n",
            "jaxlib 0.3.0+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.16.0 which is incompatible.\n",
            "jax 0.3.1 requires numpy>=1.19, but you have numpy 1.16.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 0.25.3 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.13.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cupy-cuda111 9.4.0 requires numpy<1.24,>=1.17, but you have numpy 1.16.0 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.16.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.9.0 attrdict-2.0.1 deepspeech-0.9.3 numpy-1.16.0 pandas-0.25.3 progressbar2-3.47.0 python-utils-2.3.0 six-1.13.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from -r requirements_tests.txt (line 1)) (0.9.0)\n",
            "Collecting argparse\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: semver in /usr/local/lib/python3.7/dist-packages (from -r requirements_tests.txt (line 3)) (2.13.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->-r requirements_tests.txt (line 1)) (1.13.0)\n",
            "Installing collected packages: argparse\n",
            "Successfully installed argparse-1.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting webrtcvad\n",
            "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 18.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20 kB 19.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 30 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 40 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 66 kB 2.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: webrtcvad\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp37-cp37m-linux_x86_64.whl size=72442 sha256=89a4bed7b5b885962db06009a5e1389215e53cc9fc496b012e4b3e5677b81073\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/f9/67/a3158d131f57e1c0a7d8d966a707d4a2fb27567a4fe47723ad\n",
            "Successfully built webrtcvad\n",
            "Installing collected packages: webrtcvad\n",
            "Successfully installed webrtcvad-2.0.10\n",
            "Collecting pip==20.3.0\n",
            "  Downloading pip-20.3-py2.py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting wheel==0.34.2\n",
            "  Downloading wheel-0.34.2-py2.py3-none-any.whl (26 kB)\n",
            "Collecting setuptools==49.6.0\n",
            "  Downloading setuptools-49.6.0-py3-none-any.whl (803 kB)\n",
            "\u001b[K     |████████████████████████████████| 803 kB 40.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: wheel, setuptools, pip\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.37.1\n",
            "    Uninstalling wheel-0.37.1:\n",
            "      Successfully uninstalled wheel-0.37.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "xarray 0.18.2 requires numpy>=1.17, but you have numpy 1.16.0 which is incompatible.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.16.0 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.16.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 0.25.3 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.13.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed pip-20.3 setuptools-49.6.0 wheel-0.34.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/DeepSpeech\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.16.0)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (3.47.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.13.0)\n",
            "Requirement already satisfied: attrdict in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (2.0.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (0.9.0)\n",
            "Requirement already satisfied: semver in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (2.13.0)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (0.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (0.25.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (2.23.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (0.8.1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (0.10.3.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.13.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.13.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->deepspeech-training==0.9.3) (4.6.3)\n",
            "Collecting ds_ctcdecoder==0.9.3\n",
            "  Downloading ds_ctcdecoder-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.16.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (1.6.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (0.2.2)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (0.10.3.post1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (4.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (21.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (2.1.9)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.16.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (1.0.2)\n",
            "Collecting llvmlite==0.31.0\n",
            "  Downloading llvmlite-0.31.0-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting numba==0.47.0\n",
            "  Downloading numba-0.47.0-cp37-cp37m-manylinux1_x86_64.whl (3.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7 MB 41.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.47.0->deepspeech-training==0.9.3) (49.6.0)\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 55.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna->deepspeech-training==0.9.3) (1.4.32)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (21.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna->deepspeech-training==0.9.3) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.16.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna->deepspeech-training==0.9.3) (4.63.0)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.6-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 45.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic->optuna->deepspeech-training==0.9.3) (4.11.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna->deepspeech-training==0.9.3) (5.4.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna->deepspeech-training==0.9.3) (1.4.32)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->deepspeech-training==0.9.3) (3.0.7)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna->deepspeech-training==0.9.3) (3.13)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->deepspeech-training==0.9.3) (3.2.0)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.16.0)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.0-py3-none-any.whl (150 kB)\n",
            "\u001b[K     |████████████████████████████████| 150 kB 47.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->deepspeech-training==0.9.3) (3.10.0.2)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->deepspeech-training==0.9.3) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic->optuna->deepspeech-training==0.9.3) (4.11.2)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->deepspeech-training==0.9.3) (21.4.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->deepspeech-training==0.9.3) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic->optuna->deepspeech-training==0.9.3) (3.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic->optuna->deepspeech-training==0.9.3) (3.7.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna->deepspeech-training==0.9.3) (2.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic->optuna->deepspeech-training==0.9.3) (4.11.2)\n",
            "Collecting opuslib==2.0.0\n",
            "  Downloading opuslib-2.0.0.tar.gz (7.3 kB)\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->deepspeech-training==0.9.3) (3.0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas->deepspeech-training==0.9.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->deepspeech-training==0.9.3) (2018.9)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 50.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->deepspeech-training==0.9.3) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (21.3)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->deepspeech-training==0.9.3) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic->optuna->deepspeech-training==0.9.3) (4.11.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.13.0)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2->deepspeech-training==0.9.3) (2.3.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.13.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.13.0)\n",
            "Collecting pyxdg\n",
            "  Downloading pyxdg-0.27-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->deepspeech-training==0.9.3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->deepspeech-training==0.9.3) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->deepspeech-training==0.9.3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->deepspeech-training==0.9.3) (3.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.16.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.13.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa->deepspeech-training==0.9.3) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa->deepspeech-training==0.9.3) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile->deepspeech-training==0.9.3) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile->deepspeech-training==0.9.3) (2.21)\n",
            "Collecting sox\n",
            "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna->deepspeech-training==0.9.3) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic->optuna->deepspeech-training==0.9.3) (4.11.2)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic->optuna->deepspeech-training==0.9.3) (4.11.2)\n",
            "Collecting tensorflow==1.15.4\n",
            "  Downloading tensorflow-1.15.4-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (1.13.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (3.17.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (0.34.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (0.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (1.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.16.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (1.44.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.13.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.13.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.13.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.4->deepspeech-training==0.9.3) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.16.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.4->deepspeech-training==0.9.3) (1.5.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.13.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.13.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 32.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.16.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->deepspeech-training==0.9.3) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.47.0->deepspeech-training==0.9.3) (49.6.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->deepspeech-training==0.9.3) (3.3.6)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (1.44.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (0.34.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.9.3) (1.13.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.3) (3.17.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic->optuna->deepspeech-training==0.9.3) (4.11.2)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 33.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: opuslib, pyperclip, gast\n",
            "  Building wheel for opuslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opuslib: filename=opuslib-2.0.0-py3-none-any.whl size=11009 sha256=095f2044c30965c47c61c74dc2aabbfd0b2d3f8fd040c57c21eb8fa7ce5bc6fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/ba/d4/0e81231a9797fbb262ae3a54fd761fab850db7f32d94a3283a\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11107 sha256=4aa2d07edcb59b8ecb80b104d0e01e83733459e2ce20ace75d8b2df940348e28\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=154440ca233e74974ff4c3f90bc7d08e64218e51615f11ab7c0d4fdee8a04728\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built opuslib pyperclip gast\n",
            "Installing collected packages: pyperclip, pbr, llvmlite, stevedore, numba, Mako, cmd2, autopage, tensorflow-estimator, tensorboard, keras-applications, gast, colorlog, cmaes, cliff, alembic, tensorflow, sox, pyxdg, opuslib, optuna, ds-ctcdecoder, deepspeech-training\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "  Running setup.py develop for deepspeech-training\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.16.0 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.4 which is incompatible.\u001b[0m\n",
            "Successfully installed Mako-1.2.0 alembic-1.7.6 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.0 colorlog-6.6.0 deepspeech-training ds-ctcdecoder-0.9.3 gast-0.2.2 keras-applications-1.0.8 llvmlite-0.31.0 numba-0.47.0 optuna-2.10.0 opuslib-2.0.0 pbr-5.8.1 pyperclip-1.8.2 pyxdg-0.27 sox-1.4.1 stevedore-3.5.0 tensorboard-1.15.0 tensorflow-1.15.4 tensorflow-estimator-1.15.1\n"
          ]
        }
      ],
      "source": [
        "%cd DeepSpeech\n",
        "!pip3 install -r requirements_eval_tflite.txt\n",
        "!pip3 install -r requirements_tests.txt\n",
        "!pip3 install -r requirements_transcribe.txt\n",
        "!pip3 install --upgrade pip==20.3.0 wheel==0.34.2 setuptools==49.6.0\n",
        "!pip3 install --upgrade -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KMOWfBMXySL"
      },
      "source": [
        "# Install Tensorflow GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iav8orKxNd35",
        "outputId": "202c4a50-f5d8-4bd8-f607-b07f79617c02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 1.15.4\n",
            "Uninstalling tensorflow-1.15.4:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/freeze_graph\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-1.15.4.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow_core/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-1.15.4\n",
            "Collecting tensorflow-gpu==1.15.4\n",
            "  Downloading tensorflow_gpu-1.15.4-cp37-cp37m-manylinux2010_x86_64.whl (411.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 411.0 MB 25 kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.44.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.13.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.13.3)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.15.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (3.17.3)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.15.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.16.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.13.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.13.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.13.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.4) (3.1.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.16.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15.4) (1.5.2)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.16.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.13.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.16.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.13.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.13.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (3.3.6)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.44.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (49.6.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (0.34.2)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.16.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (3.10.0.2)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.15.4\n"
          ]
        }
      ],
      "source": [
        "!pip3 uninstall tensorflow\n",
        "!pip3 install 'tensorflow-gpu==1.15.4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFxqO-yypuDd",
        "outputId": "ba7ef0a3-9688-4964-a1b3-9737d393cf2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "python3-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install python3-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USQv3Oq9OC_K",
        "outputId": "925110bf-995c-43aa-edb4-ac4d4f8b6ef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSpeech\n"
          ]
        }
      ],
      "source": [
        "%cd /content/DeepSpeech"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne9HR-WTX-EA"
      },
      "source": [
        "# Install Library SoX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS08lscoOnss",
        "outputId": "598ad6b6-38e2-4b2a-c0c4-b634e3d4d0bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libid3tag0 libmad0 libmagic-mgc libmagic1 libopencore-amrnb0\n",
            "  libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base libsox3\n",
            "Suggested packages:\n",
            "  file libsox-fmt-all\n",
            "The following NEW packages will be installed:\n",
            "  libid3tag0 libmad0 libmagic-mgc libmagic1 libopencore-amrnb0\n",
            "  libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base libsox-fmt-mp3 libsox3\n",
            "  sox\n",
            "0 upgraded, 11 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 872 kB of archives.\n",
            "After this operation, 7,087 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopencore-amrnb0 amd64 0.1.3-2.1 [92.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopencore-amrwb0 amd64 0.1.3-2.1 [45.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libid3tag0 amd64 0.15.1b-13 [31.2 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libmad0 amd64 0.15.1b-9ubuntu18.04.1 [64.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox3 amd64 14.4.2-3ubuntu0.18.04.1 [226 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2-3ubuntu0.18.04.1 [10.6 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox-fmt-base amd64 14.4.2-3ubuntu0.18.04.1 [32.1 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox-fmt-mp3 amd64 14.4.2-3ubuntu0.18.04.1 [15.9 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 sox amd64 14.4.2-3ubuntu0.18.04.1 [101 kB]\n",
            "Fetched 872 kB in 1s (823 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 11.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "(Reading database ... 155335 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libopencore-amrnb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../01-libopencore-amrwb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "Preparing to unpack .../02-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../03-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libid3tag0:amd64.\n",
            "Preparing to unpack .../04-libid3tag0_0.15.1b-13_amd64.deb ...\n",
            "Unpacking libid3tag0:amd64 (0.15.1b-13) ...\n",
            "Selecting previously unselected package libmad0:amd64.\n",
            "Preparing to unpack .../05-libmad0_0.15.1b-9ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking libmad0:amd64 (0.15.1b-9ubuntu18.04.1) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../06-libsox3_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../07-libsox-fmt-alsa_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../08-libsox-fmt-base_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-mp3:amd64.\n",
            "Preparing to unpack .../09-libsox-fmt-mp3_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-mp3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package sox.\n",
            "Preparing to unpack .../10-sox_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libid3tag0:amd64 (0.15.1b-13) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up libmad0:amd64 (0.15.1b-9ubuntu18.04.1) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-mp3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,628 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,256 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,478 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,067 kB]\n",
            "Fetched 9,685 kB in 3s (3,137 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "sox is already the newest version (14.4.2-3ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install sox libsox-fmt-mp3\n",
        "!apt-get -y update && apt-get install -y sox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hILAfNLYac6X"
      },
      "outputs": [],
      "source": [
        "# !sudo apt update"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvaZ1oBkYIZm"
      },
      "source": [
        "# Import dan Konversi Dataset dari .tsv ke .csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPfc8Gfd4p0j",
        "outputId": "a105fe9a-89cb-4e7d-af28-7a8f72db26de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSpeech\n",
            "Loading TSV file:  /content/cv/id/test.tsv\n",
            "Importing mp3 files...\n",
            "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
            "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
            "Progress |##################################################### |  98% completedImported 3598 samples.\n",
            "Skipped 10 samples that failed on transcript validation.\n",
            "Final amount of imported audio: 4:04:11 from 4:05:01.\n",
            "Saving new DeepSpeech-formatted CSV file to:  /content/cv/id/clips/test.csv\n",
            "Writing CSV file for DeepSpeech.py as:  /content/cv/id/clips/test.csv\n",
            "Progress |######################################################| 100% completed\n",
            "Loading TSV file:  /content/cv/id/dev.tsv\n",
            "Importing mp3 files...\n",
            "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
            "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
            "Progress |######################################################| 100% completedImported 3180 samples.\n",
            "Skipped 24 samples that failed on transcript validation.\n",
            "Skipped 3 samples that were longer than 10 seconds.\n",
            "Final amount of imported audio: 3:39:59 from 3:42:48.\n",
            "Saving new DeepSpeech-formatted CSV file to:  /content/cv/id/clips/dev.csv\n",
            "Writing CSV file for DeepSpeech.py as:  /content/cv/id/clips/dev.csv\n",
            "Progress |######################################################| 100% completed\n",
            "Loading TSV file:  /content/cv/id/train.tsv\n",
            "Importing mp3 files...\n",
            "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
            "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
            "Progress |######################################################| 100% completedImported 4889 samples.\n",
            "Skipped 126 samples that failed on transcript validation.\n",
            "Skipped 17 samples that were longer than 10 seconds.\n",
            "Final amount of imported audio: 7:28:50 from 7:43:50.\n",
            "Saving new DeepSpeech-formatted CSV file to:  /content/cv/id/clips/train.csv\n",
            "Writing CSV file for DeepSpeech.py as:  /content/cv/id/clips/train.csv\n",
            "Progress |######################################################| 100% completed\n",
            "Loading TSV file:  /content/cv/id/validated.tsv\n",
            "Importing mp3 files...\n",
            "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
            "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
            "Progress |##################################################### |  98% completedImported 22676 samples.\n",
            "Skipped 174 samples that failed on transcript validation.\n",
            "Skipped 24 samples that were longer than 10 seconds.\n",
            "Final amount of imported audio: 27:33:04 from 27:53:41.\n",
            "Saving new DeepSpeech-formatted CSV file to:  /content/cv/id/clips/validated.csv\n",
            "Writing CSV file for DeepSpeech.py as:  /content/cv/id/clips/validated.csv\n",
            "Progress |######################################################| 100% completed\n",
            "Saving new DeepSpeech-formatted CSV file to:  /content/cv/id/clips/train-all.csv\n",
            "Writing CSV file for DeepSpeech.py as:  /content/cv/id/clips/train-all.csv\n",
            "Progress |######################################################| 100% completed\n",
            "Loading TSV file:  /content/cv/id/other.tsv\n",
            "Importing mp3 files...\n",
            "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
            "WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.\n",
            "Progress |######################################################| 100% completedImported 22338 samples.\n",
            "Skipped 40 samples that failed on transcript validation.\n",
            "Skipped 7 samples that were longer than 10 seconds.\n",
            "Final amount of imported audio: 23:09:52 from 23:14:30.\n",
            "Saving new DeepSpeech-formatted CSV file to:  /content/cv/id/clips/other.csv\n",
            "Writing CSV file for DeepSpeech.py as:  /content/cv/id/clips/other.csv\n",
            "Progress |######################################################| 100% completed\n",
            "Progress |######################################################| 100% completed\n",
            "Progress |######################################################| 100% completed\n",
            "Progress |######################################################| 100% completed\n",
            "Progress |######################################################| 100% completed\n",
            "Progress |######################################################| 100% completed\n"
          ]
        }
      ],
      "source": [
        "%cd /content/DeepSpeech\n",
        "!bin/import_cv2.py --filter_alphabet /content/DeepSpeech/data/alphabet.txt /content/cv/id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSQp6r6sa4M5"
      },
      "outputs": [],
      "source": [
        "!python3 -m deepspeech_training.util.check_characters -alpha -unicode -csv \\\n",
        "/content/cv/id/clips/train.csv,/content/cv/id/clips/dev.csv,/content/cv/id/clips/test.csv >> data/alphabet.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUJFG4k29LkT"
      },
      "source": [
        "# Membuat Language Model A.k.a Scorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwD1b3Vm2CQO",
        "outputId": "38b026de-f427-4680-9d13-7d903d69562e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSpeech/kenlm\n",
            "--2022-03-14 06:01:11--  https://kheafield.com/code/kenlm.tar.gz\n",
            "Resolving kheafield.com (kheafield.com)... 35.196.63.85\n",
            "Connecting to kheafield.com (kheafield.com)|35.196.63.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 491888 (480K) [application/x-gzip]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>] 480.36K  2.72MB/s    in 0.2s    \n",
            "\n",
            "2022-03-14 06:01:11 (2.72 MB/s) - written to stdout [491888/491888]\n",
            "\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Could NOT find Eigen3 (missing: Eigen3_DIR)\n",
            "-- Looking for pthread.h\n",
            "-- Looking for pthread.h - found\n",
            "-- Looking for pthread_create\n",
            "-- Looking for pthread_create - not found\n",
            "-- Looking for pthread_create in pthreads\n",
            "-- Looking for pthread_create in pthreads - not found\n",
            "-- Looking for pthread_create in pthread\n",
            "-- Looking for pthread_create in pthread - found\n",
            "-- Found Threads: TRUE  \n",
            "-- Boost version: 1.65.1\n",
            "-- Found the following Boost libraries:\n",
            "--   program_options\n",
            "--   system\n",
            "--   thread\n",
            "--   unit_test_framework\n",
            "--   chrono\n",
            "--   date_time\n",
            "--   atomic\n",
            "-- Check if compiler accepts -pthread\n",
            "-- Check if compiler accepts -pthread - yes\n",
            "-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n",
            "-- Found BZip2: /usr/lib/x86_64-linux-gnu/libbz2.so (found version \"1.0.6\") \n",
            "-- Looking for BZ2_bzCompressInit\n",
            "-- Looking for BZ2_bzCompressInit - found\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Found LibLZMA: /usr/include (found version \"5.2.2\") \n",
            "-- Looking for clock_gettime in rt\n",
            "-- Looking for clock_gettime in rt - found\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/DeepSpeech/kenlm\n",
            "\u001b[35m\u001b[1mScanning dependencies of target kenlm_util\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/diy-fp.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum-dtoa.cc.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/cached-powers.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/double-conversion.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fast-dtoa.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fixed-dtoa.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/strtod.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/chain.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/count_records.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/io.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/line_input.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/multi_progress.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/rewindable_stream.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/bit_packing.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/ersatz_progress.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/exception.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file_piece.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/float_to_string.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/integer_to_string.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/mmap.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/murmur_hash.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/parallel_read.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/pool.cc.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/read_compressed.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/scoped.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/spaces.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/string_piece.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/usage.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm_util.a\u001b[0m\n",
            "[ 38%] Built target kenlm_util\n",
            "\u001b[35m\u001b[1mScanning dependencies of target probing_hash_table_benchmark\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target kenlm\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target kenlm_filter\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object util/CMakeFiles/probing_hash_table_benchmark.dir/probing_hash_table_benchmark_main.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/bhiksha.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/phrase.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/arpa_io.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/binary_format.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/vocab.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/config.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/lm_exception.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/model.cc.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/quantize.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_filter.a\u001b[0m\n",
            "[ 52%] Built target kenlm_filter\n",
            "[ 53%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/read_arpa.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_hashed.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_trie.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/sizes.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie_sort.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32m\u001b[1mLinking CXX executable ../bin/probing_hash_table_benchmark\u001b[0m\n",
            "[ 61%] Built target probing_hash_table_benchmark\n",
            "[ 62%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/value_build.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/virtual_interface.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/vocab.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/model_buffer.cc.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/print.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/renumber.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/size_option.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm.a\u001b[0m\n",
            "[ 71%] Built target kenlm\n",
            "\u001b[35m\u001b[1mScanning dependencies of target build_binary\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target fragment\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target kenlm_benchmark\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target query\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm_benchmark.dir/kenlm_benchmark_main.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object lm/CMakeFiles/build_binary.dir/build_binary_main.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object lm/CMakeFiles/fragment.dir/fragment_main.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object lm/CMakeFiles/query.dir/query_main.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32m\u001b[1mLinking CXX executable ../bin/fragment\u001b[0m\n",
            "[ 77%] Built target fragment\n",
            "[ 78%] \u001b[32m\u001b[1mLinking CXX executable ../bin/build_binary\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target kenlm_builder\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/adjust_counts.cc.o\u001b[0m\n",
            "[ 80%] Built target build_binary\n",
            "\u001b[35m\u001b[1mScanning dependencies of target phrase_table_vocab\u001b[0m\n",
            "[ 81%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/phrase_table_vocab.dir/phrase_table_vocab_main.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32m\u001b[1mLinking CXX executable ../bin/query\u001b[0m\n",
            "[ 82%] Built target query\n",
            "\u001b[35m\u001b[1mScanning dependencies of target filter\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/filter.dir/filter_main.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/phrase_table_vocab\u001b[0m\n",
            "[ 85%] Built target phrase_table_vocab\n",
            "[ 86%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/corpus_count.cc.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/initial_probabilities.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/interpolate.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/output.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/pipeline.cc.o\u001b[0m\n",
            "[ 92%] \u001b[32m\u001b[1mLinking CXX executable ../bin/kenlm_benchmark\u001b[0m\n",
            "[ 92%] Built target kenlm_benchmark\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/filter\u001b[0m\n",
            "[ 93%] Built target filter\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_builder.a\u001b[0m\n",
            "[ 95%] Built target kenlm_builder\n",
            "\u001b[35m\u001b[1mScanning dependencies of target count_ngrams\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target lmplz\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/lmplz.dir/lmplz_main.cc.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/count_ngrams.dir/count_ngrams_main.cc.o\u001b[0m\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/lmplz\u001b[0m\n",
            "[ 98%] Built target lmplz\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/count_ngrams\u001b[0m\n",
            "[100%] Built target count_ngrams\n"
          ]
        }
      ],
      "source": [
        "%cd /content/DeepSpeech/kenlm/\n",
        "!wget -O - https://kheafield.com/code/kenlm.tar.gz |tar xz\n",
        "!cd kenlm\n",
        "!mkdir build\n",
        "!cmake kenlm\n",
        "!make -j 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ykb38F_DqZ-l",
        "outputId": "77e03239-61c1-4fd5-ee14-705dcf78fbec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSpeech\n"
          ]
        }
      ],
      "source": [
        "%cd /content/DeepSpeech\n",
        "!mkdir deepspeech-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaWbJONr9WvZ",
        "outputId": "c6ebcaa2-2196-4e42-bdc4-5eace5845cde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSpeech/deepspeech-data\n"
          ]
        }
      ],
      "source": [
        "%cd /content/DeepSpeech/deepspeech-data\n",
        "!mkdir indonesian-scorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXM7zEtl-gj3",
        "outputId": "9153d237-e785-4a1d-88e5-515feaa54b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSpeech/data/lm\n",
            "\n",
            "Converting to lowercase and counting word occurrences ...\n",
            "| |    #                                           | 13917 Elapsed Time: 0:00:00\n",
            "\n",
            "Saving top 500000 words ...\n",
            "\n",
            "Calculating word statistics ...\n",
            "  Your text file has 306093 words in total\n",
            "  It has 32506 unique words\n",
            "  Your top-500000 words are 100.0000 percent of all words\n",
            "  Your most common word \"yang\" occurred 8484 times\n",
            "  The least common word in your top-k is \"peregangan\" with 1 times\n",
            "  The first word with 2 occurrences is \"shuffler.\" at place 15026\n",
            "\n",
            "Creating ARPA file ...\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/DeepSpeech/deepspeech-data/indonesian-scorer/lower.txt.gz\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "tcmalloc: large alloc 2038890496 bytes == 0x564547b88000 @  0x7fe361ef81e7 0x5645459cb7e2 0x5645459664fe 0x5645459452eb 0x564545931066 0x7fe360091c87 0x564545932baa\n",
            "tcmalloc: large alloc 9514811392 bytes == 0x5645c13f8000 @  0x7fe361ef81e7 0x5645459cb7e2 0x5645459ba80a 0x5645459bb248 0x564545945308 0x564545931066 0x7fe360091c87 0x564545932baa\n",
            "****************************************************************************************************\n",
            "Unigram tokens 306093 types 32509\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:390108 2:1129606912 3:2118013056 4:3388820736 5:4942030848\n",
            "tcmalloc: large alloc 4942036992 bytes == 0x564547a7e000 @  0x7fe361ef81e7 0x5645459cb7e2 0x5645459ba80a 0x5645459bb248 0x5645459458d7 0x564545931066 0x7fe360091c87 0x564545932baa\n",
            "tcmalloc: large alloc 2118017024 bytes == 0x5646b1946000 @  0x7fe361ef81e7 0x5645459cb7e2 0x5645459ba80a 0x5645459bb248 0x564545945cdd 0x564545931066 0x7fe360091c87 0x564545932baa\n",
            "tcmalloc: large alloc 3388825600 bytes == 0x5647f8e94000 @  0x7fe361ef81e7 0x5645459cb7e2 0x5645459ba80a 0x5645459bb248 0x564545945cdd 0x564545931066 0x7fe360091c87 0x564545932baa\n",
            "Statistics:\n",
            "1 32509 D1=0.692142 D2=0.987899 D3+=1.27378\n",
            "2 180582 D1=0.824037 D2=1.19322 D3+=1.46766\n",
            "3 20280/251584 D1=0.936166 D2=1.43049 D3+=1.75178\n",
            "4 11464/257965 D1=0.97735 D2=1.63598 D3+=1.82504\n",
            "5 8535/250723 D1=0.943791 D2=1.66787 D3+=1.84871\n",
            "Memory estimate for binary LM:\n",
            "type      kB\n",
            "probing 5951 assuming -p 1.5\n",
            "probing 7322 assuming -r models -p 1.5\n",
            "trie    3216 without quantization\n",
            "trie    1981 assuming -q 8 -b 8 quantization \n",
            "trie    2939 assuming -a 22 array pointer compression\n",
            "trie    1704 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:390108 2:2889312 3:405600 4:275136 5:238980\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "***#################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:390108 2:2889312 3:405600 4:275136 5:238980\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:15043516 kB\tVmRSS:2038696 kB\tRSSMax:2041616 kB\tuser:0.622023\tsys:1.23312\tCPU:1.85519\treal:1.72288\n",
            "\n",
            "Filtering ARPA file using vocabulary of top-k words ...\n",
            "Reading /content/DeepSpeech/deepspeech-data/indonesian-scorer/lm.arpa\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "\n",
            "Building lm.binary ...\n",
            "Reading /content/DeepSpeech/deepspeech-data/indonesian-scorer/lm_filtered.arpa\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Identifying n-grams omitted by SRI\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Quantizing\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Writing trie\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "SUCCESS\n"
          ]
        }
      ],
      "source": [
        "%cd /content/DeepSpeech/data/lm/\n",
        "!python3 generate_lm.py \\\n",
        "  --input_txt /content/gdrive/MyDrive/deepspeech-data/indonesian_sentence.txt \\\n",
        "  --output_dir /content/DeepSpeech/deepspeech-data/indonesian-scorer \\\n",
        "  --top_k 500000 --kenlm_bins /content/DeepSpeech/kenlm/bin \\\n",
        "  --arpa_order 5 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
        "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPMJBWFvJSN6",
        "outputId": "165c1b97-ecab-4c97-9f2a-6151c49e781b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-14 06:36:40--  https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/native_client.amd64.cuda.linux.tar.xz\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/60273704/41d8a080-3b15-11eb-87d9-8c3ab703f1c3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220314%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220314T063640Z&X-Amz-Expires=300&X-Amz-Signature=5cbe2d9f4f159110d5df76e1cf8517f6de9c44ba048387a8aced5face3ee643f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Dnative_client.amd64.cuda.linux.tar.xz&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-03-14 06:36:40--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/60273704/41d8a080-3b15-11eb-87d9-8c3ab703f1c3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220314%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220314T063640Z&X-Amz-Expires=300&X-Amz-Signature=5cbe2d9f4f159110d5df76e1cf8517f6de9c44ba048387a8aced5face3ee643f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Dnative_client.amd64.cuda.linux.tar.xz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14086680 (13M) [application/octet-stream]\n",
            "Saving to: ‘native_client.amd64.cuda.linux.tar.xz’\n",
            "\n",
            "native_client.amd64 100%[===================>]  13.43M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-03-14 06:36:41 (114 MB/s) - ‘native_client.amd64.cuda.linux.tar.xz’ saved [14086680/14086680]\n",
            "\n",
            "libdeepspeech.so\n",
            "generate_scorer_package\n",
            "LICENSE\n",
            "deepspeech\n",
            "deepspeech.h\n",
            "README.mozilla\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/native_client.amd64.cuda.linux.tar.xz\n",
        "!tar -Jxvf native_client.amd64.cuda.linux.tar.xz -C /content/DeepSpeech/data/lm/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef_WCsh6-1o1",
        "outputId": "d3bd6d7c-9bdf-4cc1-aa14-b3a854c97306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSpeech/data/lm\n",
            "32506 unique words read from vocabulary file.\n",
            "Doesn't look like a character based (Bytes Are All You Need) model.\n",
            "Package created in kenlm-indonesian.scorer.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/DeepSpeech/data/lm/\n",
        "!./generate_scorer_package \\\n",
        "  --alphabet /content/DeepSpeech/data/alphabet.txt  \\\n",
        "  --lm /content/DeepSpeech/deepspeech-data/indonesian-scorer/lm.binary \\\n",
        "  --vocab /content/DeepSpeech/deepspeech-data/indonesian-scorer/vocab-500000.txt \\\n",
        "  --package kenlm-indonesian.scorer \\\n",
        "  --default_alpha 0.931289039105002 \\\n",
        "  --default_beta 1.1834137581510284 \\\n",
        "  --force_bytes_output_mode True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX1D5nHOs47l",
        "outputId": "c28b265e-62ff-4ca7-9061-e62d8362b8b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSpeech\n",
            "\u001b[32m[I 2022-03-14 06:37:07,345]\u001b[0m A new study created in memory with name: no-name-d0d7b7c9-097f-4fa5-8269-3890cdc4a119\u001b[0m\n",
            "I0314 06:37:07.954865 140013685380992 utils.py:159] NumExpr defaulting to 2 threads.\n",
            "I Could not find best validating checkpoint.\n",
            "I Could not find most recent checkpoint.\n",
            "E All initialization methods failed (['best', 'last']).\n"
          ]
        }
      ],
      "source": [
        "%cd /content/DeepSpeech\n",
        "!python3 lm_optimizer.py \\\n",
        "     --test_files /content/DeepSpeech/cv/id/clips/test.csv \\\n",
        "     --checkpoint_dir /content/DeepSpeech/deepspeech-data/checkpoint \\\n",
        "     --alphabet_config_path /content/DeepSpeech/data/alphabet.txt \\\n",
        "     --n_hidden 4 \\\n",
        "     --n_trials 3 \\\n",
        "     --lm_alpha_max 0.92 \\\n",
        "     --lm_beta_max 1.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyv69olA-uuw",
        "outputId": "89b7a541-e0bf-49a1-9e53-c27cb975b9c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   674  100   674    0     0   5616      0 --:--:-- --:--:-- --:--:--  5616\n",
            "100 13.4M  100 13.4M    0     0  39.7M      0 --:--:-- --:--:-- --:--:-- 39.7M\n",
            "libdeepspeech.so\n",
            "generate_scorer_package\n",
            "LICENSE\n",
            "deepspeech\n",
            "deepspeech.h\n",
            "README.mozilla\n"
          ]
        }
      ],
      "source": [
        "!curl -L https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/native_client.amd64.cuda.linux.tar.xz -o native_client.amd64.cuda.linux.tar.xz && tar -Jxvf native_client.amd64.cuda.linux.tar.xz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/DeepSpeech/data/lm/\n",
        "!./generate_scorer_package \\\n",
        "  --alphabet /content/DeepSpeech/data/alphabet.txt  \\\n",
        "  --lm /content/DeepSpeech/deepspeech-data/indonesian-scorer/lm.binary \\\n",
        "  --vocab /content/DeepSpeech/deepspeech-data/indonesian-scorer/vocab-500000.txt \\\n",
        "  --package kenlm-indonesian.scorer \\\n",
        "  --default_alpha 0.931289039105002 \\\n",
        "  --default_beta 1.1834137581510284 \\\n",
        "  --force_bytes_output_mode True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAWKhwS2xln7",
        "outputId": "653a9d28-b539-4898-f92a-c0a32d4a4456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSpeech/data/lm\n",
            "32506 unique words read from vocabulary file.\n",
            "Doesn't look like a character based (Bytes Are All You Need) model.\n",
            "Package created in kenlm-indonesian.scorer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cBqu1oi_Jcq",
        "outputId": "cb147056-f662-4c18-9fb1-3bd493bec771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSpeech/data/lm\n"
          ]
        }
      ],
      "source": [
        "%cd /content/DeepSpeech/data/lm/\n",
        "!cp kenlm-indonesian.scorer /content/DeepSpeech/deepspeech-data/indonesian-scorer/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PbXTo3j_K5G",
        "outputId": "bdb4429c-ce7c-416b-9e39-58a01314da7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 81084\n",
            "    4 drwxr-xr-x 2 root root        4096 Mar 10 06:35 .\n",
            "    4 drwxr-xr-x 5 root root        4096 Mar 10 05:57 ..\n",
            "  928 -rwxr-xr-x 1  105 nogroup   946808 Dec 10  2020 deepspeech\n",
            "   16 -rw-r--r-- 1  105 nogroup    14057 Dec 10  2020 deepspeech.h\n",
            "    8 -rw-r--r-- 1 root root        6452 Mar 10 05:57 generate_lm.py\n",
            " 2624 -r-xr-xr-x 1  105 nogroup  2683144 Dec 10  2020 generate_scorer_package\n",
            " 5460 -rw-r--r-- 1 root root     5588544 Mar 10 06:35 kenlm-indonesian.scorer\n",
            "58256 -r-xr-xr-x 1  105 nogroup 59649896 Dec 10  2020 libdeepspeech.so\n",
            "   20 -rw-r--r-- 1  105 nogroup    16725 Aug 26  2020 LICENSE\n",
            "13760 -rw-r--r-- 1 root root    14086680 Dec  8 05:19 native_client.amd64.cuda.linux.tar.xz\n",
            "    4 -rw-r--r-- 1  105 nogroup      554 Aug 26  2020 README.mozilla\n"
          ]
        }
      ],
      "source": [
        "!ls -las"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3CyDjGpYylx"
      },
      "source": [
        "# Membuat Acoustic Model dan Training DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIIqoLW8XvbE",
        "outputId": "2a8b1957-efb9-49f8-9e38-20147481be05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSpeech\n",
            "I0314 06:39:18.841224 140268707800960 utils.py:159] NumExpr defaulting to 2 threads.\n",
            "I Could not find best validating checkpoint.\n",
            "I Could not find most recent checkpoint.\n",
            "I Initializing all variables.\n",
            "I STARTING Optimization\n",
            "Epoch 0 |   Training | Elapsed Time: 0:01:33 | Steps: 611 | Loss: 212.902135    \n",
            "Epoch 0 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 124.664660 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 124.664660 to: /content/gdrive/MyDrive/Deepspeech/best_dev-611\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 1 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 177.772574    \n",
            "Epoch 1 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 123.484086 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 123.484086 to: /content/gdrive/MyDrive/Deepspeech/best_dev-1222\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 2 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 161.143590    \n",
            "Epoch 2 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 114.022836 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 114.022836 to: /content/gdrive/MyDrive/Deepspeech/best_dev-1833\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 3 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 139.013101    \n",
            "Epoch 3 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 106.605241 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 106.605241 to: /content/gdrive/MyDrive/Deepspeech/best_dev-2444\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 4 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 125.960057    \n",
            "Epoch 4 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 102.554747 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 102.554747 to: /content/gdrive/MyDrive/Deepspeech/best_dev-3055\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 5 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 117.963207    \n",
            "Epoch 5 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 100.479276 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 100.479276 to: /content/gdrive/MyDrive/Deepspeech/best_dev-3666\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 6 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 112.133302    \n",
            "Epoch 6 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 99.330296 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 99.330296 to: /content/gdrive/MyDrive/Deepspeech/best_dev-4277\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 7 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 107.346594    \n",
            "Epoch 7 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 98.228769 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 98.228769 to: /content/gdrive/MyDrive/Deepspeech/best_dev-4888\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 8 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 103.290199    \n",
            "Epoch 8 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 97.175050 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 97.175050 to: /content/gdrive/MyDrive/Deepspeech/best_dev-5499\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 9 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 99.597391     \n",
            "Epoch 9 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 96.224844 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 96.224844 to: /content/gdrive/MyDrive/Deepspeech/best_dev-6110\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 10 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 96.467698    \n",
            "Epoch 10 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 95.778140 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 95.778140 to: /content/gdrive/MyDrive/Deepspeech/best_dev-6721\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 11 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 93.714204    \n",
            "Epoch 11 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 94.519904 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 94.519904 to: /content/gdrive/MyDrive/Deepspeech/best_dev-7332\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 12 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 91.103286    \n",
            "Epoch 12 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 94.322812 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 94.322812 to: /content/gdrive/MyDrive/Deepspeech/best_dev-7943\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 13 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 88.836336    \n",
            "Epoch 13 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 93.460501 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 93.460501 to: /content/gdrive/MyDrive/Deepspeech/best_dev-8554\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 14 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 86.743562    \n",
            "Epoch 14 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 93.096061 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 93.096061 to: /content/gdrive/MyDrive/Deepspeech/best_dev-9165\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 15 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 84.840780    \n",
            "Epoch 15 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 92.878823 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 92.878823 to: /content/gdrive/MyDrive/Deepspeech/best_dev-9776\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 16 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 83.126993    \n",
            "Epoch 16 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 92.183927 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 92.183927 to: /content/gdrive/MyDrive/Deepspeech/best_dev-10387\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 17 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 81.407323    \n",
            "Epoch 17 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 91.967016 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 91.967016 to: /content/gdrive/MyDrive/Deepspeech/best_dev-10998\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 18 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 79.864305    \n",
            "Epoch 18 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 91.610383 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 91.610383 to: /content/gdrive/MyDrive/Deepspeech/best_dev-11609\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 19 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 78.462753    \n",
            "Epoch 19 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 91.469871 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 91.469871 to: /content/gdrive/MyDrive/Deepspeech/best_dev-12220\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 20 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 77.128122    \n",
            "Epoch 20 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 90.990171 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 90.990171 to: /content/gdrive/MyDrive/Deepspeech/best_dev-12831\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 21 |   Training | Elapsed Time: 0:01:28 | Steps: 611 | Loss: 75.871744    \n",
            "Epoch 21 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 91.005165 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 22 |   Training | Elapsed Time: 0:01:28 | Steps: 611 | Loss: 74.830499    \n",
            "Epoch 22 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 90.693062 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 90.693062 to: /content/gdrive/MyDrive/Deepspeech/best_dev-14053\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 23 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 73.564039    \n",
            "Epoch 23 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 90.609293 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 90.609293 to: /content/gdrive/MyDrive/Deepspeech/best_dev-14664\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 24 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 72.573039    \n",
            "Epoch 24 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 90.707818 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 25 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 71.485655    \n",
            "Epoch 25 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 90.165896 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 90.165896 to: /content/gdrive/MyDrive/Deepspeech/best_dev-15886\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 26 |   Training | Elapsed Time: 0:01:28 | Steps: 611 | Loss: 70.669636    \n",
            "Epoch 26 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 89.924221 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 89.924221 to: /content/gdrive/MyDrive/Deepspeech/best_dev-16497\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 27 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 69.804446    \n",
            "Epoch 27 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 89.734139 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 89.734139 to: /content/gdrive/MyDrive/Deepspeech/best_dev-17108\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 28 |   Training | Elapsed Time: 0:01:28 | Steps: 611 | Loss: 68.885523    \n",
            "Epoch 28 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 90.031291 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 29 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 67.909839    \n",
            "Epoch 29 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 89.572639 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 89.572639 to: /content/gdrive/MyDrive/Deepspeech/best_dev-18330\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 30 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 67.338567    \n",
            "Epoch 30 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 89.088608 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 89.088608 to: /content/gdrive/MyDrive/Deepspeech/best_dev-18941\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 31 |   Training | Elapsed Time: 0:01:28 | Steps: 611 | Loss: 66.492380    \n",
            "Epoch 31 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 89.375303 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 32 |   Training | Elapsed Time: 0:01:28 | Steps: 611 | Loss: 65.745017    \n",
            "Epoch 32 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 89.489943 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 33 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 65.070337    \n",
            "Epoch 33 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 89.213615 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 34 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 64.489828    \n",
            "Epoch 34 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 88.993695 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 88.993695 to: /content/gdrive/MyDrive/Deepspeech/best_dev-21385\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 35 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 63.780055    \n",
            "Epoch 35 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 89.579782 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 36 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 63.219591    \n",
            "Epoch 36 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.867431 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 88.867431 to: /content/gdrive/MyDrive/Deepspeech/best_dev-22607\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 37 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 62.509986    \n",
            "Epoch 37 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.677110 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 88.677110 to: /content/gdrive/MyDrive/Deepspeech/best_dev-23218\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 38 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 61.980491    \n",
            "Epoch 38 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.914895 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 39 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 61.558017    \n",
            "Epoch 39 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.623580 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 88.623580 to: /content/gdrive/MyDrive/Deepspeech/best_dev-24440\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 40 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 60.975734    \n",
            "Epoch 40 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.385555 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 88.385555 to: /content/gdrive/MyDrive/Deepspeech/best_dev-25051\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 41 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 60.382510    \n",
            "Epoch 41 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.747057 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 42 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 60.010573    \n",
            "Epoch 42 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.205440 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 88.205440 to: /content/gdrive/MyDrive/Deepspeech/best_dev-26273\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 43 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 59.529615    \n",
            "Epoch 43 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 88.604611 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 44 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 58.992691    \n",
            "Epoch 44 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.234718 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 45 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 58.621166    \n",
            "Epoch 45 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.394921 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 46 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 58.257897    \n",
            "Epoch 46 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 88.468228 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 47 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 57.738722    \n",
            "Epoch 47 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.224210 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 48 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 57.199571    \n",
            "Epoch 48 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.556550 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 49 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 56.922886    \n",
            "Epoch 49 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.386273 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 50 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 56.500163    \n",
            "Epoch 50 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.539745 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 51 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 56.081971    \n",
            "Epoch 51 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.193961 | Dataset: /content/cv/id/clips/dev.csv\n",
            "I Saved new best validating model with loss 88.193961 to: /content/gdrive/MyDrive/Deepspeech/best_dev-31772\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 52 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 55.786165    \n",
            "Epoch 52 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 88.333708 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 53 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 55.367051    \n",
            "Epoch 53 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.468490 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 54 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 55.006806    \n",
            "Epoch 54 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.314244 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 55 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 54.700035    \n",
            "Epoch 55 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.557680 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 56 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 54.412695    \n",
            "Epoch 56 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.431291 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 57 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 53.991740    \n",
            "Epoch 57 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.572535 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 58 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 53.713868    \n",
            "Epoch 58 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.861526 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 59 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 53.409538    \n",
            "Epoch 59 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.365902 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 60 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 53.013624    \n",
            "Epoch 60 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 88.627546 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 61 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 52.846688    \n",
            "Epoch 61 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.549894 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 62 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 52.443951    \n",
            "Epoch 62 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 88.530715 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 63 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 52.195996    \n",
            "Epoch 63 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.980670 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 64 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 52.010634    \n",
            "Epoch 64 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.587505 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 65 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 51.702828    \n",
            "Epoch 65 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.372172 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 66 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 51.441487    \n",
            "Epoch 66 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.574723 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 67 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 51.150096    \n",
            "Epoch 67 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 89.122208 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 68 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 50.839979    \n",
            "Epoch 68 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 88.847250 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 69 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 50.646091    \n",
            "Epoch 69 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.912633 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 70 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 50.440514    \n",
            "Epoch 70 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.639459 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 71 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 50.097647    \n",
            "Epoch 71 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 89.333972 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 72 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 49.795753    \n",
            "Epoch 72 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.600829 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 73 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 49.615623    \n",
            "Epoch 73 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.538756 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 74 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 49.496175    \n",
            "Epoch 74 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.502303 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 75 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 49.107658    \n",
            "Epoch 75 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.858813 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 76 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 49.016179    \n",
            "Epoch 76 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 89.142323 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 77 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 48.682798    \n",
            "Epoch 77 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 89.200044 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 78 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 48.516555    \n",
            "Epoch 78 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 88.692208 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 79 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 48.387474    \n",
            "Epoch 79 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 89.292166 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 80 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 48.086919    \n",
            "Epoch 80 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 89.294101 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 81 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 47.789901    \n",
            "Epoch 81 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 88.919593 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 82 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 47.715409    \n",
            "Epoch 82 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 89.602637 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 83 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 47.422745    \n",
            "Epoch 83 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 89.446112 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 84 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 47.245418    \n",
            "Epoch 84 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 89.221265 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 85 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 46.973930    \n",
            "Epoch 85 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 89.457473 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 86 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 46.868836    \n",
            "Epoch 86 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 89.410568 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 87 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 46.736215    \n",
            "Epoch 87 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 89.484659 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 88 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 46.590721    \n",
            "Epoch 88 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 90.027118 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 89 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 46.309891    \n",
            "Epoch 89 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 89.651031 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 90 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 46.248741    \n",
            "Epoch 90 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 89.399768 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 91 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 46.009898    \n",
            "Epoch 91 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 89.692215 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 92 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 45.794287    \n",
            "Epoch 92 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 89.658294 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 93 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 45.636996    \n",
            "Epoch 93 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 89.707716 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 94 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 45.498936    \n",
            "Epoch 94 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 89.608672 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 95 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 45.338111    \n",
            "Epoch 95 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 90.488370 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 96 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 45.049282    \n",
            "Epoch 96 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 90.346081 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 97 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 44.962201    \n",
            "Epoch 97 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 89.562707 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 98 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 44.741911    \n",
            "Epoch 98 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 90.325241 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 99 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 44.629069    \n",
            "Epoch 99 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 90.095498 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 100 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 44.453320   \n",
            "Epoch 100 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 90.341764 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 101 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 44.321052   \n",
            "Epoch 101 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 90.120577 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 102 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 44.202330   \n",
            "Epoch 102 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 90.756366 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 103 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 44.057014   \n",
            "Epoch 103 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 90.450204 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 104 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 43.973244   \n",
            "Epoch 104 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 90.091440 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 105 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 43.746854   \n",
            "Epoch 105 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 90.276856 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 106 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 43.595403   \n",
            "Epoch 106 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 90.701867 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 107 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 43.490616   \n",
            "Epoch 107 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 90.656514 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 108 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 43.398489   \n",
            "Epoch 108 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 90.628028 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 109 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 43.152887   \n",
            "Epoch 109 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 91.259237 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 110 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 43.049232   \n",
            "Epoch 110 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 90.797230 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 111 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 42.898385   \n",
            "Epoch 111 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 90.519669 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 112 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 42.820383   \n",
            "Epoch 112 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 90.524158 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 113 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 42.818648   \n",
            "Epoch 113 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 90.929034 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 114 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 42.536373   \n",
            "Epoch 114 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 90.551868 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 115 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 42.425933   \n",
            "Epoch 115 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 90.828158 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 116 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 42.180205   \n",
            "Epoch 116 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 90.817097 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 117 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 42.193887   \n",
            "Epoch 117 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 91.159651 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 118 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 42.164908   \n",
            "Epoch 118 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 90.767142 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 119 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 41.889329   \n",
            "Epoch 119 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 91.642938 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 120 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 41.829551   \n",
            "Epoch 120 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 91.579257 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 121 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 41.726834   \n",
            "Epoch 121 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 91.209950 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 122 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 41.498015   \n",
            "Epoch 122 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 91.563507 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 123 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 41.510069   \n",
            "Epoch 123 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 90.965130 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 124 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 41.352631   \n",
            "Epoch 124 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 92.342849 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 125 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 41.170083   \n",
            "Epoch 125 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 92.029504 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 126 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 41.093389   \n",
            "Epoch 126 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 91.772800 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 127 |   Training | Elapsed Time: 0:01:28 | Steps: 611 | Loss: 41.025061   \n",
            "Epoch 127 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 92.019544 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 128 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 40.940503   \n",
            "Epoch 128 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 91.264003 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 129 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 40.803398   \n",
            "Epoch 129 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 91.505433 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 130 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 40.665579   \n",
            "Epoch 130 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 91.829416 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 131 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 40.623872   \n",
            "Epoch 131 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 91.966984 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 132 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 40.446721   \n",
            "Epoch 132 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 92.050472 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 133 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 40.418904   \n",
            "Epoch 133 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 92.455850 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 134 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 40.174810   \n",
            "Epoch 134 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 92.356438 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 135 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 40.162891   \n",
            "Epoch 135 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 92.136719 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 136 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 39.979095   \n",
            "Epoch 136 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 92.040358 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 137 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 39.823424   \n",
            "Epoch 137 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 92.150059 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 138 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 39.910986   \n",
            "Epoch 138 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 92.264605 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 139 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 39.800903   \n",
            "Epoch 139 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 93.004918 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 140 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 39.626570   \n",
            "Epoch 140 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 93.351240 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 141 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 39.498261   \n",
            "Epoch 141 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 92.569917 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 142 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 39.468203   \n",
            "Epoch 142 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 92.450286 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 143 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 39.393200   \n",
            "Epoch 143 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 92.550645 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 144 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 39.326855   \n",
            "Epoch 144 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 92.921552 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 145 |   Training | Elapsed Time: 0:01:26 | Steps: 611 | Loss: 39.256616   \n",
            "Epoch 145 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 92.838677 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 146 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 39.077211   \n",
            "Epoch 146 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 92.913359 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 147 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 38.989112   \n",
            "Epoch 147 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 93.551928 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 148 |   Training | Elapsed Time: 0:01:28 | Steps: 611 | Loss: 38.828019   \n",
            "Epoch 148 | Validation | Elapsed Time: 0:00:22 | Steps: 398 | Loss: 92.429126 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 149 |   Training | Elapsed Time: 0:01:27 | Steps: 611 | Loss: 38.811888   \n",
            "Epoch 149 | Validation | Elapsed Time: 0:00:23 | Steps: 398 | Loss: 93.374920 | Dataset: /content/cv/id/clips/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "I FINISHED optimization in 4:36:11.124417\n",
            "I Loading best validating checkpoint from /content/gdrive/MyDrive/Deepspeech/best_dev-31772\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
            "I Loading variable from checkpoint: global_step\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "Testing model on /content/cv/id/clips/test.csv\n",
            "Test epoch | Steps: 6 | Elapsed Time: 0:01:09                                   "
          ]
        }
      ],
      "source": [
        "%cd /content/DeepSpeech\n",
        "!python3 DeepSpeech.py \\\n",
        "  --epochs 150 \\\n",
        "  --n_hidden 100 \\\n",
        "  --learning_rate 0.0001 \\\n",
        "  --alphabet_config_path /content/DeepSpeech/data/alphabet.txt \\\n",
        "  --train_files /content/cv/id/clips/train.csv \\\n",
        "  --dev_files /content/cv/id/clips/dev.csv \\\n",
        "  --test_files /content/cv/id/clips/test.csv \\\n",
        "  --checkpoint_dir /content/gdrive/MyDrive/Deepspeech/ \\\n",
        "  --export_dir /content/gdrive/MyDrive/Deepspeech/Models/ --export_file_name 'indo_model' \\\n",
        "  --train_batch_size 8 --dev_batch_size 8 --test_batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCtH07ZqedQs"
      },
      "outputs": [],
      "source": [
        "! python3 DeepSpeech.py \\\n",
        "    --test_files /content/cv/id/clips/test.csv \\\n",
        "    --checkpoint_dir /content/gdrive/MyDrive/Deepspeech \\\n",
        "    --test_batch_size 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIYfNY9Y_khU"
      },
      "source": [
        "# Convert Model Pb ke Pbmm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0a1EtBLdgWA",
        "outputId": "1e624401-7e4a-4b28-9102-182b7325ade0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/DeepSpeech\n",
            "Downloading https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.tensorflow.pip.r1.15.cpu/artifacts/public/convert_graphdef_memmapped_format ...\n",
            "Downloading: 100%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cd /content/DeepSpeech\n",
        "!python3 /content/DeepSpeech/util/taskcluster.py --source tensorflow --artifact convert_graphdef_memmapped_format --branch r1.15 --target ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7YzlHBg9_ID",
        "outputId": "df22939a-fcc1-4d06-9339-5b54270cbcc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-02-20 12:07:13.919018: I tensorflow/contrib/util/convert_graphdef_memmapped_format_lib.cc:171] Converted 5 nodes\n"
          ]
        }
      ],
      "source": [
        "! ./convert_graphdef_memmapped_format \\\n",
        "--in_graph=/content/gdrive/MyDrive/Deepspeech/Models/indo_model.pb \\\n",
        "--out_graph=/content/gdrive/MyDrive/Deepspeech/Models/indo_model.pbmm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIfFv50JCB8p"
      },
      "source": [
        "# Using Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD3pwDbJCBgQ",
        "outputId": "d7b94305-61f1-4a6f-d604-e2a7e317bfab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting deepspeech-gpu\n",
            "  Downloading deepspeech_gpu-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from deepspeech-gpu) (1.16.0)\n",
            "Installing collected packages: deepspeech-gpu\n",
            "Successfully installed deepspeech-gpu-0.9.3\n"
          ]
        }
      ],
      "source": [
        "! pip3 install deepspeech-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykRH_UG4CI0D",
        "outputId": "e978e5a7-9ad9-4904-81ad-5e8dd736bc17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-02-20 12:35:29.859887: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Loading model from file /content/gdrive/MyDrive/Deepspeech/Models/indo_model.pbmm\n",
            "TensorFlow: v2.3.0-6-g23ad988\n",
            "DeepSpeech: v0.9.3-0-gf2e9c85\n",
            "2022-02-20 12:35:29.971677: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-02-20 12:35:29.972700: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2022-02-20 12:35:30.003077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-02-20 12:35:30.003734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2022-02-20 12:35:30.003765: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-02-20 12:35:30.005696: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2022-02-20 12:35:30.006642: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2022-02-20 12:35:30.006955: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2022-02-20 12:35:30.008968: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-02-20 12:35:30.009945: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-02-20 12:35:30.013577: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-02-20 12:35:30.013673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-02-20 12:35:30.014296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-02-20 12:35:30.014799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2022-02-20 12:35:30.502667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-02-20 12:35:30.502712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2022-02-20 12:35:30.502725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2022-02-20 12:35:30.502903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-02-20 12:35:30.503532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-02-20 12:35:30.504114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-02-20 12:35:30.504640: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-02-20 12:35:30.504679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14069 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Loaded model in 0.547s.\n",
            "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
            "Running inference.\n",
            "2022-02-20 12:35:30.800102: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "saya tedula umateku sebegilan\n",
            "Inference took 0.735s for 3.744s audio file.\n"
          ]
        }
      ],
      "source": [
        "! deepspeech --model /content/gdrive/MyDrive/Deepspeech/Models/indo_model.pbmm \\\n",
        "--audio /content/gdrive/MyDrive/dataset/Salinan_common_voice_id_19059670.wav \\\n",
        "--scorer /content/DeepSpeech/deepspeech-data/indonesian-scorer/kenlm-indonesian.scorer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIlqlDtt_sam"
      },
      "source": [
        "# Training data Versi Lain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBgD_SYbHko3",
        "outputId": "04b15359-a9f0-452b-8a49-6e45252f7b3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-126:\n",
            "Process ForkPoolWorker-125:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
            "    res = self._reader.recv_bytes()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python3 DeepSpeech.py \\\n",
        "  --train_files /content/DeepSpeech/cv/id/clips/train.csv \\\n",
        "  --dev_files /content/DeepSpeech/cv/id/clips/dev.csv \\\n",
        "  --test_files /content/DeepSpeech/cv/id/clips/test.csv \\\n",
        "  --checkpoint_dir /content/gdrive/MyDrive/Deepspeech/ \\ --export_dir /content/gdrive/MyDrive/Deepspeech/Models/ --export_file_name 'indo_model' \\ --scorer_path /content/drive/MyDrive/urdu_scorer/kenlm-indonesian.scorer \\ --n_hidden 64 --reduce_lr_on_plateau true --plateau_epochs 8 --plateau_reduction 0.08 --early_stop true --es_epochs 10 --es_min_delta 0.06 --dropout_rate 0.3 --train_batch_size 8 --dev_batch_size 8 --test_batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ig84agOOLZre"
      },
      "outputs": [],
      "source": [
        "# !python3 DeepSpeech.py --helpfull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wYYK4IpityF"
      },
      "outputs": [],
      "source": [
        "# !python3 DeepSpeech.py \\\n",
        "#   --train_files deepspeech-data/cv/id/clips/train.csv \\\n",
        "#   --dev_files deepspeech-data/cv/id/clips/dev.csv \\\n",
        "#   --test_files deepspeech-data/cv/id/clips/test.csv \\\n",
        "#   --checkpoint_dir deepspeech-data/checkpoints \\\n",
        "#   --export_dir deepspeech-data/exported-model \\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAZcRLTFHBIB"
      },
      "outputs": [],
      "source": [
        "# !python3 DeepSpeech.py --n_hidden 2048 --checkpoint_dir path/to/checkpoint/folder --epochs 3 --train_files my-train.csv --dev_files my-dev.csv --test_files my_dev.csv --learning_rate 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9prC5ibTPg8v"
      },
      "outputs": [],
      "source": [
        "# !python3 DeepSpeech.py --train_files ../cv/id/clips/train.csv --dev_files ../cv/id/clips/dev.csv --test_files ../cv/id/clips/test.csv"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "YyQu4BQgXMik",
        "7UKVVMgIYXCG",
        "Jq-PZaHerfdG",
        "kIlqlDtt_sam"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}